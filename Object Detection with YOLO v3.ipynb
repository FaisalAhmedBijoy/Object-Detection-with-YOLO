{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration YOLO \n",
    "readNet(model[, config[, framework]]) -> retval\n",
    "   * @brief Read deep learning network represented in one of the supported formats.\n",
    "   * @param[in] model Binary file contains trained weights. The following file\n",
    "   *                  extensions are expected for models from different frameworks:\n",
    "   *                  * `*.caffemodel` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "   *                  * `*.pb` (TensorFlow, https://www.tensorflow.org/)\n",
    "   *                  * `*.t7` | `*.net` (Torch, http://torch.ch/)\n",
    "   *                  * `*.weights` (Darknet, https://pjreddie.com/darknet/)\n",
    "   *                  * `*.bin` (DLDT, https://software.intel.com/openvino-toolkit)\n",
    "   * @param[in] config Text file contains network configuration. It could be a\n",
    "   *                   file with the following extensions:\n",
    "   *                  * `*.prototxt` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "   *                  * `*.pbtxt` (TensorFlow, https://www.tensorflow.org/)\n",
    "   *                  * `*.cfg` (Darknet, https://pjreddie.com/darknet/)\n",
    "   *                  * `*.xml` (DLDT, https://software.intel.com/openvino-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=cv2.dnn.readNet('yolov3.weights','yolov3.cfg')\n",
    "classes=[]\n",
    "with open('classes.txt','r') as f:\n",
    "    classes=f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes:  80\n",
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print('Total classes: ', len(classes))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Image for object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('dhaka.jpg')\n",
    "cv2.imshow('Input Image: ',image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (728, 1092, 3)\n",
      "728\n",
      "1092\n"
     ]
    }
   ],
   "source": [
    "print('Image shape: ',image.shape)\n",
    "height,width,channel=image.shape\n",
    "print(height)\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728, 1092, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_input_image=np.copy(image)\n",
    "yolo_input_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob from Image\n",
    "blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=cv2.dnn.blobFromImage(yolo_input_image,1/255,(416,416),(0,0,0),swapRB=True,crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 416, 416)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 416, 416)\n"
     ]
    }
   ],
   "source": [
    "for b in blob:\n",
    "    print(b.shape)\n",
    "    # indicate that there are 3 channel and each channel image size is: (image.height x image.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in blob:\n",
    "    for channel,img_blob in enumerate(b):\n",
    "        cv2.imshow(str(channel),img_blob)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize YOLO with Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_82', 'yolo_94', 'yolo_106']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layers_name=net.getUnconnectedOutLayersNames()\n",
    "output_layers_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs forward pass to compute output of layer with name @p outputName.\n",
    "layerOutputs=net.forward(output_layers_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layerOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046930425"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layerOutputs[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Box Parameter, Confidence and Class ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "confidences=[]\n",
    "class_ids=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.6930425e-02, 5.9314493e-02, 3.5881579e-01, 1.3749062e-01,\n",
       "       7.6460975e-07, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First four parameters are: center x, center y, box width , box height\n",
    "# Others parametre indicate the predicted class id\n",
    "layerOutputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores=detection[5:]\n",
    "        class_id=np.argmax(scores)\n",
    "        confidence=scores[class_id]\n",
    "        if confidence>0.5:\n",
    "            center_x=int(detection[0]*width)\n",
    "            center_y=int(detection[1]*height)\n",
    "            w=int(detection[2]*width)\n",
    "            h=int(detection[3]*height)\n",
    "            \n",
    "            x=int(center_x -(w/2))\n",
    "            y=int(center_y -(h/2))\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box found:  28\n",
      "[[544, 274, 394, 329], [571, 275, 403, 328], [846, 333, 238, 217], [1, 278, 408, 432], [581, 350, 324, 231], [569, 339, 358, 259], [596, 353, 336, 224], [568, 335, 394, 263], [832, 347, 253, 211], [-1, 306, 416, 423], [859, 168, 125, 87], [875, 168, 114, 90], [869, 168, 123, 88], [932, 210, 146, 114], [921, 203, 163, 135], [945, 210, 132, 108], [939, 202, 147, 135], [718, 242, 186, 105], [973, 258, 108, 88], [962, 257, 121, 85], [971, 266, 115, 102], [969, 265, 120, 96], [852, 340, 220, 208], [864, 338, 218, 209], [853, 343, 217, 219], [868, 347, 215, 210], [468, 333, 46, 42], [493, 333, 42, 44]]\n"
     ]
    }
   ],
   "source": [
    "print('Box found: ',len(boxes))\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Maximum Supression \n",
    "NMSBoxes(bboxes, scores, score_threshold, nms_threshold[, eta[, top_k]]) -> indices\n",
    "\n",
    "If the two boxes are correlated with each other. we have to choose one box rather than two.In this scenario, <b>NMSBoxes</b> removes the lower scores bounding box if two boxes are mixed with each others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(confidences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(boxes[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7],\n",
       "       [23],\n",
       "       [ 9],\n",
       "       [13],\n",
       "       [12],\n",
       "       [17],\n",
       "       [21],\n",
       "       [26],\n",
       "       [27]], dtype=int32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes=cv2.dnn.NMSBoxes(boxes,confidences,0.3,0.4)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Non Maximum Suppression (NMS):  9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7, 23,  9, 13, 12, 17, 21, 26, 27], dtype=int32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After Non Maximum Suppression (NMS): ',len(indexes))\n",
    "indexes.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the Bounding Box on Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "font=cv2.FONT_HERSHEY_PLAIN\n",
    "colors=np.random.uniform(0,255,size=(len(boxes),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 19.90513279,  49.56840863, 161.18821238],\n",
       "       [ 64.36747371, 155.95425526,  30.46626505],\n",
       "       [ 36.14544398,  93.89337979,  16.00911333],\n",
       "       [ 25.12795897, 176.39593166, 231.65665047],\n",
       "       [ 56.7487865 , 200.71060253,  55.66131638],\n",
       "       [146.70746689, 168.17493496,  24.07010431],\n",
       "       [ 68.57313134, 104.909529  , 145.55551153],\n",
       "       [ 11.72108112,  56.16427584,  35.14877474],\n",
       "       [211.66528696, 116.42250393,  41.04197861],\n",
       "       [153.22031364, 149.52552277, 152.49725188],\n",
       "       [ 10.76398402, 202.04742487,  87.6226121 ],\n",
       "       [ 52.74961958, 124.85932483, 171.513004  ],\n",
       "       [176.76307723, 108.27098059,  96.19931761],\n",
       "       [158.36927735, 203.04535335,  92.81860275],\n",
       "       [115.56783829, 133.58715651, 127.76572716],\n",
       "       [ 31.19625164, 220.60007796,  84.55116929],\n",
       "       [197.94501329, 235.4800697 , 182.01947316],\n",
       "       [134.11796916, 206.55960655,   5.8475993 ],\n",
       "       [189.16096071, 157.08031859,  66.17371366],\n",
       "       [162.45255426,  97.7711949 ,  52.66393967],\n",
       "       [201.84265189,  76.55204375,  65.0391586 ],\n",
       "       [ 33.06430475, 241.62048938, 171.59975308],\n",
       "       [181.52172201,  86.95448968,  42.20081613],\n",
       "       [248.90709817, 128.73050406, 169.24650152],\n",
       "       [235.71282802,  90.33231346, 241.41934989],\n",
       "       [206.97833683,  97.63932019,  50.12558334],\n",
       "       [205.85390592, 181.52950918, 108.49173045],\n",
       "       [172.81604913, 115.99823623,  88.2529437 ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(colors.shape)\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(indexes)>0:\n",
    "    for i in indexes.flatten():\n",
    "        x,y,w,h=boxes[i]\n",
    "        label=str(classes[class_ids[i]])\n",
    "        color=colors[i]\n",
    "        confidence=str(round(confidences[i],2))\n",
    "        \n",
    "        cv2.rectangle(yolo_input_image,(x,y),(x+w,y+h),color,2)\n",
    "        cv2.putText(yolo_input_image,label+' '+confidence,(x,y+20),font,2,(0,0,255),2 )\n",
    "cv2.imshow('YOLO Input',image)\n",
    "cv2.imshow('YOLO Output',yolo_input_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
